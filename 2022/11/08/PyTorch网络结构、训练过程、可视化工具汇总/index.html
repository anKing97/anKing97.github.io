<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>PyTorch网络结构、训练过程、可视化工具汇总 | shallow shadow</title><meta name="author" content="浅羡"><meta name="copyright" content="浅羡"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="一、网络结构的可视化我们训练神经网络时，除了随着 step 或者 epoch 观察损失函数的走势，从而建立对目前网络优化的基本认知外，也可以通过一些额外的可视化库来可视化我们的神经网络结构图。这将更加地高效地向读者展现目前的网络结构。为了可视化神经网络，我们先建立一个简单的卷积层神经网络： 123456789101112131415161718192021222324252627282930313">
<meta property="og:type" content="article">
<meta property="og:title" content="PyTorch网络结构、训练过程、可视化工具汇总">
<meta property="og:url" content="https://www.zl21.club/2022/11/08/PyTorch%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E3%80%81%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B%E3%80%81%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B7%A5%E5%85%B7%E6%B1%87%E6%80%BB/index.html">
<meta property="og:site_name" content="shallow shadow">
<meta property="og:description" content="一、网络结构的可视化我们训练神经网络时，除了随着 step 或者 epoch 观察损失函数的走势，从而建立对目前网络优化的基本认知外，也可以通过一些额外的可视化库来可视化我们的神经网络结构图。这将更加地高效地向读者展现目前的网络结构。为了可视化神经网络，我们先建立一个简单的卷积层神经网络： 123456789101112131415161718192021222324252627282930313">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://images.pexels.com/photos/1252890/pexels-photo-1252890.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=1260&amp;h=750&amp;dpr=2">
<meta property="article:published_time" content="2022-11-08T09:05:22.000Z">
<meta property="article:modified_time" content="2023-01-01T15:30:41.000Z">
<meta property="article:author" content="浅羡">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="PyTorch">
<meta property="article:tag" content="可视化工具">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://images.pexels.com/photos/1252890/pexels-photo-1252890.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=1260&amp;h=750&amp;dpr=2"><link rel="shortcut icon" href="/img/IronMan.png"><link rel="canonical" href="https://www.zl21.club/2022/11/08/PyTorch%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E3%80%81%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B%E3%80%81%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B7%A5%E5%85%B7%E6%B1%87%E6%80%BB/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'PyTorch网络结构、训练过程、可视化工具汇总',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-01-01 23:30:41'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/modify.css"><meta name="baidu-site-verification" content="codeva-VKYv5KPH3d"><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">14</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">24</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://images.pexels.com/photos/1252890/pexels-photo-1252890.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=1260&amp;h=750&amp;dpr=2')"><nav id="nav"><span id="blog-info"><a href="/" title="shallow shadow"><span class="site-name">shallow shadow</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">PyTorch网络结构、训练过程、可视化工具汇总</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-11-08T09:05:22.000Z" title="发表于 2022-11-08 17:05:22">2022-11-08</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-01-01T15:30:41.000Z" title="更新于 2023-01-01 23:30:41">2023-01-01</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Python/">Python</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Python/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">4.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>16分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="PyTorch网络结构、训练过程、可视化工具汇总"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><div class="top-img" style="background-image: url('https://images.pexels.com/photos/1252890/pexels-photo-1252890.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=1260&amp;h=750&amp;dpr=2');"></div><article class="post-content" id="article-container"><h1 id="一、网络结构的可视化"><a href="#一、网络结构的可视化" class="headerlink" title="一、网络结构的可视化"></a>一、网络结构的可视化</h1><p>我们训练神经网络时，除了随着 step 或者 epoch 观察损失函数的走势，从而建立对目前网络优化的基本认知外，也可以通过一些额外的可视化库来可视化我们的神经网络结构图。这将更加地高效地向读者展现目前的网络结构。<br>为了可视化神经网络，我们先建立一个简单的卷积层神经网络：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>&nbsp;torch  </span><br><span class="line">&nbsp;<span class="keyword">import</span>&nbsp;torch.nn&nbsp;<span class="keyword">as</span>&nbsp;nn  </span><br><span class="line">&nbsp;  </span><br><span class="line">&nbsp;<span class="keyword">class</span>&nbsp;<span class="title class_">ConvNet</span>(nn.Module):  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword">def</span>&nbsp;<span class="title function_">__init__</span>(<span class="params">self</span>):  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="built_in">super</span>(ConvNet,&nbsp;self).__init__()  </span><br><span class="line">&nbsp;  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.conv1&nbsp;=&nbsp;nn.Sequential(  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nn.Conv2d(<span class="number">1</span>,&nbsp;<span class="number">16</span>,&nbsp;<span class="number">3</span>,&nbsp;<span class="number">1</span>,&nbsp;<span class="number">1</span>),  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nn.ReLU(),  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nn.AvgPool2d(<span class="number">2</span>,&nbsp;<span class="number">2</span>)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;)  </span><br><span class="line">&nbsp;  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.conv2&nbsp;=&nbsp;nn.Sequential(  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nn.Conv2d(<span class="number">16</span>,&nbsp;<span class="number">32</span>,&nbsp;<span class="number">3</span>,&nbsp;<span class="number">1</span>,&nbsp;<span class="number">1</span>),  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nn.ReLU(),  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nn.MaxPool2d(<span class="number">2</span>,&nbsp;<span class="number">2</span>)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;)  </span><br><span class="line">&nbsp;  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.fc&nbsp;=&nbsp;nn.Sequential(  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nn.Linear(<span class="number">32</span>&nbsp;*&nbsp;<span class="number">7</span>&nbsp;*&nbsp;<span class="number">7</span>,&nbsp;<span class="number">128</span>),  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nn.ReLU(),  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nn.Linear(<span class="number">128</span>,&nbsp;<span class="number">64</span>),  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nn.ReLU()  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;)  </span><br><span class="line">&nbsp;  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.out&nbsp;=&nbsp;nn.Linear(<span class="number">64</span>,&nbsp;<span class="number">10</span>)  </span><br><span class="line">&nbsp;  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword">def</span>&nbsp;<span class="title function_">forward</span>(<span class="params">self,&nbsp;x</span>):  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;self.conv1(x)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;self.conv2(x)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;x.view(x.size(<span class="number">0</span>),&nbsp;-<span class="number">1</span>)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;self.fc(x)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;output&nbsp;=&nbsp;self.out(x)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword">return</span>&nbsp;output</span><br></pre></td></tr></tbody></table></figure>
<p>输出网络结构：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&nbsp;MyConvNet&nbsp;=&nbsp;ConvNet()  </span><br><span class="line">&nbsp;<span class="built_in">print</span>(MyConvNet)</span><br></pre></td></tr></tbody></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&nbsp;ConvNet(  </span><br><span class="line">&nbsp;&nbsp;&nbsp;(conv1):&nbsp;Sequential(  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(<span class="number">0</span>):&nbsp;Conv2d(<span class="number">1</span>,&nbsp;<span class="number">16</span>,&nbsp;kernel_size=(<span class="number">3</span>,&nbsp;<span class="number">3</span>),&nbsp;stride=(<span class="number">1</span>,&nbsp;<span class="number">1</span>),&nbsp;padding=(<span class="number">1</span>,&nbsp;<span class="number">1</span>))  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(<span class="number">1</span>):&nbsp;ReLU()  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(<span class="number">2</span>):&nbsp;AvgPool2d(kernel_size=<span class="number">2</span>,&nbsp;stride=<span class="number">2</span>,&nbsp;padding=<span class="number">0</span>)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;(conv2):&nbsp;Sequential(  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(<span class="number">0</span>):&nbsp;Conv2d(<span class="number">16</span>,&nbsp;<span class="number">32</span>,&nbsp;kernel_size=(<span class="number">3</span>,&nbsp;<span class="number">3</span>),&nbsp;stride=(<span class="number">1</span>,&nbsp;<span class="number">1</span>),&nbsp;padding=(<span class="number">1</span>,&nbsp;<span class="number">1</span>))  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(<span class="number">1</span>):&nbsp;ReLU()  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(<span class="number">2</span>):&nbsp;MaxPool2d(kernel_size=<span class="number">2</span>,&nbsp;stride=<span class="number">2</span>,&nbsp;padding=<span class="number">0</span>,&nbsp;dilation=<span class="number">1</span>,&nbsp;ceil_mode=<span class="literal">False</span>)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;(fc):&nbsp;Sequential(  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(<span class="number">0</span>):&nbsp;Linear(in_features=<span class="number">1568</span>,&nbsp;out_features=<span class="number">128</span>,&nbsp;bias=<span class="literal">True</span>)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(<span class="number">1</span>):&nbsp;ReLU()  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(<span class="number">2</span>):&nbsp;Linear(in_features=<span class="number">128</span>,&nbsp;out_features=<span class="number">64</span>,&nbsp;bias=<span class="literal">True</span>)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(<span class="number">3</span>):&nbsp;ReLU()  </span><br><span class="line">&nbsp;&nbsp;&nbsp;)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;(out):&nbsp;Linear(in_features=<span class="number">64</span>,&nbsp;out_features=<span class="number">10</span>,&nbsp;bias=<span class="literal">True</span>)  </span><br><span class="line">&nbsp;)</span><br></pre></td></tr></tbody></table></figure>
<p>有了基本的神经网络后，我们分别通过 <code>HiddenLayer</code> 和 <code>PyTorchViz</code> 库来可视化上述的卷积层神经网络。</p>
<blockquote>
<p>需要说明的是，这两个库都是基于 Graphviz 开发的，因此倘若你的电脑上没有安装并且没有添加环境变量，请自行安装 Graphviz 工具，安装教程</p>
</blockquote>
<h2 id="1-1-通过-HiddenLayer-可视化网络"><a href="#1-1-通过-HiddenLayer-可视化网络" class="headerlink" title="1.1 通过 HiddenLayer 可视化网络"></a>1.1 通过 HiddenLayer 可视化网络</h2><p>首先当然是安装库啦，打开 cmd，输入：<code>pip install hiddenlayer</code><br>绘制的基本程序如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&nbsp;<span class="keyword">import</span>&nbsp;hiddenlayer&nbsp;<span class="keyword">as</span>&nbsp;h  </span><br><span class="line">&nbsp;vis_graph&nbsp;=&nbsp;h.build_graph(MyConvNet,&nbsp;torch.zeros([<span class="number">1</span>&nbsp;,<span class="number">1</span>,&nbsp;<span class="number">28</span>,&nbsp;<span class="number">28</span>]))&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;获取绘制图像的对象  </span></span><br><span class="line">&nbsp;vis_graph.theme&nbsp;=&nbsp;h.graph.THEMES[<span class="string">"blue"</span>].copy()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;指定主题颜色  </span></span><br><span class="line">&nbsp;vis_graph.save(<span class="string">"./demo1.png"</span>)&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;保存图像的路径</span></span><br></pre></td></tr></tbody></table></figure>
<p>效果如下：<img src="image-20230508170702874.png" alt="image-20230508170702874"></p>
<h2 id="1-2-通过-PyTorchViz-可视化网络"><a href="#1-2-通过-PyTorchViz-可视化网络" class="headerlink" title="1.2 通过 PyTorchViz 可视化网络"></a>1.2 通过 PyTorchViz 可视化网络</h2><p>先安装库：<code>pip install torchviz</code><br>这里我们只使用可视化函数 <code>make_dot()</code> 来获取绘图对象，基本使用和 <code>HiddenLayer</code> 差不多，不同的地方在于 <code>PyTorch</code> 绘图之前可以指定一个网络的输入值和预测值。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&nbsp;<span class="keyword">from</span>&nbsp;torchviz&nbsp;<span class="keyword">import</span>&nbsp;make_dot  </span><br><span class="line">&nbsp;x&nbsp;=&nbsp;torch.randn(<span class="number">1</span>,&nbsp;<span class="number">1</span>,&nbsp;<span class="number">28</span>,&nbsp;<span class="number">28</span>).requires_grad_(<span class="literal">True</span>)&nbsp;&nbsp;<span class="comment">#&nbsp;定义一个网络的输入值  </span></span><br><span class="line">&nbsp;y&nbsp;=&nbsp;MyConvNet(x)&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;获取网络的预测值  </span></span><br><span class="line">&nbsp;  </span><br><span class="line">&nbsp;MyConvNetVis&nbsp;=&nbsp;make_dot(y,&nbsp;params=<span class="built_in">dict</span>(<span class="built_in">list</span>(MyConvNet.named_parameters())&nbsp;+&nbsp;[(<span class="string">'x'</span>,&nbsp;x)]))  </span><br><span class="line">&nbsp;MyConvNetVis.<span class="built_in">format</span>&nbsp;=&nbsp;<span class="string">"png"</span>  </span><br><span class="line">&nbsp;<span class="comment">#&nbsp;指定文件生成的文件夹  </span></span><br><span class="line">&nbsp;MyConvNetVis.directory&nbsp;=&nbsp;<span class="string">"data"</span>  </span><br><span class="line">&nbsp;<span class="comment">#&nbsp;生成文件  </span></span><br><span class="line">&nbsp;MyConvNetVis.view()</span><br></pre></td></tr></tbody></table></figure>
<p>打开与上述代码相同根目录下的 data 文件夹，里面会有一个 <code>.gv</code> 文件和一个 <code>.png</code> 文件，其中的 <code>.gv</code> 文件是 Graphviz 工具生成图片的脚本代码，<code>.png</code> 是 <code>.gv</code> 文件编译生成的图片，直接打开 <code>.png</code> 文件就行。</p>
<blockquote>
<p>默认情况下，上述程序运行后会自动打开. png 文件</p>
</blockquote>
<p>生成图片：<img src="image-20230508170715537.png" alt="image-20230508170715537"></p>
<h1 id="二、训练过程可视化"><a href="#二、训练过程可视化" class="headerlink" title="二、训练过程可视化"></a>二、训练过程可视化</h1><p>观察我们的网络的每一步的损失函数或准确率的变化可以有效地帮助我们判断当前训练过程的优劣。如果能将这些过程可视化，那么我们判断的准确性和舒适性都会有所增加。</p>
<p>此处主要讲通过可视化神器<code>tensorboardX</code>和刚刚用到的<code>HiddenLayer</code>来实现训练过程的可视化。</p>
<p>为了训练网络，我们先导入训练网络需要的数据，此处就导入 MNIST 数据集，并做训练前的一些基本的数据处理。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">&nbsp;<span class="keyword">import</span>&nbsp;torchvision  </span><br><span class="line">&nbsp;<span class="keyword">import</span>&nbsp;torch.utils.data&nbsp;<span class="keyword">as</span>&nbsp;Data  </span><br><span class="line">&nbsp;<span class="comment">#&nbsp;准备训练用的MNIST数据集  </span></span><br><span class="line">&nbsp;train_data&nbsp;=&nbsp;torchvision.datasets.MNIST(  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;root&nbsp;=&nbsp;<span class="string">"./data/MNIST"</span>,&nbsp;&nbsp;<span class="comment">#&nbsp;提取数据的路径  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;train=<span class="literal">True</span>,&nbsp;<span class="comment">#&nbsp;使用MNIST内的训练数据  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;transform=torchvision.transforms.ToTensor(),&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;转换成torch.tensor  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;download=<span class="literal">False</span>&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;如果是第一次运行的话，置为True，表示下载数据集到root目录  </span></span><br><span class="line">&nbsp;)  </span><br><span class="line">&nbsp;  </span><br><span class="line">&nbsp;<span class="comment">#&nbsp;定义loader  </span></span><br><span class="line">&nbsp;train_loader&nbsp;=&nbsp;Data.DataLoader(  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dataset=train_data,  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;batch_size=<span class="number">128</span>,  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;shuffle=<span class="literal">True</span>,  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;num_workers=<span class="number">0</span>  </span><br><span class="line">&nbsp;)  </span><br><span class="line">&nbsp;  </span><br><span class="line">&nbsp;test_data&nbsp;=&nbsp;torchvision.datasets.MNIST(  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;root=<span class="string">"./data/MNIST"</span>,  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;train=<span class="literal">False</span>,&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;使用测试数据  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;download=<span class="literal">False</span>  </span><br><span class="line">&nbsp;)  </span><br><span class="line">&nbsp;  </span><br><span class="line">&nbsp;<span class="comment">#&nbsp;将测试数据压缩到0-1  </span></span><br><span class="line">&nbsp;test_data_x&nbsp;=&nbsp;test_data.data.<span class="built_in">type</span>(torch.FloatTensor)&nbsp;/&nbsp;<span class="number">255.0</span>  </span><br><span class="line">&nbsp;test_data_x&nbsp;=&nbsp;torch.unsqueeze(test_data_x,&nbsp;dim=<span class="number">1</span>)  </span><br><span class="line">&nbsp;test_data_y&nbsp;=&nbsp;test_data.targets  </span><br><span class="line">&nbsp;  </span><br><span class="line">&nbsp;<span class="comment">#&nbsp;打印一下测试数据和训练数据的shape  </span></span><br><span class="line">&nbsp;<span class="built_in">print</span>(<span class="string">"test_data_x.shape:"</span>,&nbsp;test_data_x.shape)  </span><br><span class="line">&nbsp;<span class="built_in">print</span>(<span class="string">"test_data_y.shape:"</span>,&nbsp;test_data_y.shape)  </span><br><span class="line">&nbsp;  </span><br><span class="line">&nbsp;<span class="keyword">for</span>&nbsp;x,&nbsp;y&nbsp;<span class="keyword">in</span>&nbsp;train_loader:  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="built_in">print</span>(x.shape)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="built_in">print</span>(y.shape)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword">break</span></span><br></pre></td></tr></tbody></table></figure>
<p>结果：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&nbsp;test_data_x.shape:&nbsp;torch.Size([<span class="number">10000</span>,&nbsp;<span class="number">1</span>,&nbsp;<span class="number">28</span>,&nbsp;<span class="number">28</span>])  </span><br><span class="line">&nbsp;test_data_y.shape:&nbsp;torch.Size([<span class="number">10000</span>])  </span><br><span class="line">&nbsp;torch.Size([<span class="number">128</span>,&nbsp;<span class="number">1</span>,&nbsp;<span class="number">28</span>,&nbsp;<span class="number">28</span>])  </span><br><span class="line">&nbsp;torch.Size([<span class="number">128</span>])</span><br></pre></td></tr></tbody></table></figure>
<h2 id="2-1-通过-tensorboardX-可视化训练过程"><a href="#2-1-通过-tensorboardX-可视化训练过程" class="headerlink" title="2.1 通过 tensorboardX 可视化训练过程"></a>2.1 通过 tensorboardX 可视化训练过程</h2><p><code>tensorboard</code> 是谷歌开发的深度学习框架 tensorflow 的一套深度学习可视化神器，在 pytorch 团队的努力下，他们开发出了 tensorboardX 来让 pytorch 的玩家也能享受 tensorboard 的福利。<br>先安装相关的库：<code>pip install tensorboardX tensorboard</code></p>
<p>并将 tensorboard. exe 所在的文件夹路径加入环境变量 path 中（比如我的 tensorboard. exe 的路径为 <code>D:\Python376\Scripts\tensorboard.exe</code>，那么就在 path 中加入 <code>D:\Python376\Scripts</code>）</p>
<p>下面是 <code>tensorboardX</code> 的使用过程。基本使用为，先通过 <code>tensorboardX</code> 下的 <code>SummaryWriter</code> 类获取一个日志编写器对象。然后通过这个对象的一组方法往日志中添加事件，即生成相应的图片，最后启动前端服务器，在 localhost 中就可以看到最终的结果了。</p>
<p>训练网络，并可视化网络训练过程的代码如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span>&nbsp;tensorboardX&nbsp;<span class="keyword">import</span>&nbsp;SummaryWriter  </span><br><span class="line">&nbsp;logger&nbsp;=&nbsp;SummaryWriter(log_dir=<span class="string">"data/log"</span>)  </span><br><span class="line">&nbsp;  </span><br><span class="line">&nbsp;<span class="comment">#&nbsp;获取优化器和损失函数  </span></span><br><span class="line">&nbsp;optimizer&nbsp;=&nbsp;torch.optim.Adam(MyConvNet.parameters(),&nbsp;lr=<span class="number">3e-4</span>)  </span><br><span class="line">&nbsp;loss_func&nbsp;=&nbsp;nn.CrossEntropyLoss()  </span><br><span class="line">&nbsp;log_step_interval&nbsp;=&nbsp;<span class="number">100</span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;记录的步数间隔  </span></span><br><span class="line">&nbsp;  </span><br><span class="line">&nbsp;<span class="keyword">for</span>&nbsp;epoch&nbsp;<span class="keyword">in</span>&nbsp;<span class="built_in">range</span>(<span class="number">5</span>):  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="built_in">print</span>(<span class="string">"epoch:"</span>,&nbsp;epoch)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;每一轮都遍历一遍数据加载器  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword">for</span>&nbsp;step,&nbsp;(x,&nbsp;y)&nbsp;<span class="keyword">in</span>&nbsp;<span class="built_in">enumerate</span>(train_loader):  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;前向计算-&gt;计算损失函数-&gt;(从损失函数)反向传播-&gt;更新网络  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;predict&nbsp;=&nbsp;MyConvNet(x)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loss&nbsp;=&nbsp;loss_func(predict,&nbsp;y)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;optimizer.zero_grad()&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;清空梯度（可以不写）  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loss.backward()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;反向传播计算梯度  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;optimizer.step()&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;更新网络  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;global_iter_num&nbsp;=&nbsp;epoch&nbsp;*&nbsp;<span class="built_in">len</span>(train_loader)&nbsp;+&nbsp;step&nbsp;+&nbsp;<span class="number">1</span>&nbsp;&nbsp;<span class="comment">#&nbsp;计算当前是从训练开始时的第几步(全局迭代次数)  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword">if</span>&nbsp;global_iter_num&nbsp;%&nbsp;log_step_interval&nbsp;==&nbsp;<span class="number">0</span>:  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;控制台输出一下  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="built_in">print</span>(<span class="string">"global_step:{},&nbsp;loss:{:.2}"</span>.<span class="built_in">format</span>(global_iter_num,&nbsp;loss.item()))  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;添加的第一条日志：损失函数-全局迭代次数  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logger.add_scalar(<span class="string">"train&nbsp;loss"</span>,&nbsp;loss.item()&nbsp;,global_step=global_iter_num)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;在测试集上预测并计算正确率  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;test_predict&nbsp;=&nbsp;MyConvNet(test_data_x)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;_,&nbsp;predict_idx&nbsp;=&nbsp;torch.<span class="built_in">max</span>(test_predict,&nbsp;<span class="number">1</span>)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;计算softmax后的最大值的索引，即预测结果  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;acc&nbsp;=&nbsp;accuracy_score(test_data_y,&nbsp;predict_idx)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;添加第二条日志：正确率-全局迭代次数  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logger.add_scalar(<span class="string">"test&nbsp;accuary"</span>,&nbsp;acc.item(),&nbsp;global_step=global_iter_num)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;添加第三条日志：这个batch下的128张图像  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;img&nbsp;=&nbsp;vutils.make_grid(x,&nbsp;nrow=<span class="number">12</span>)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logger.add_image(<span class="string">"train&nbsp;image&nbsp;sample"</span>,&nbsp;img,&nbsp;global_step=global_iter_num)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;添加第三条日志：网络中的参数分布直方图  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword">for</span>&nbsp;name,&nbsp;param&nbsp;<span class="keyword">in</span>&nbsp;MyConvNet.named_parameters():  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logger.add_histogram(name,&nbsp;param.data.numpy(),&nbsp;global_step=global_iter_num)</span><br></pre></td></tr></tbody></table></figure>
<p>运行完后，我们通过 cmd 来到与代码同一级的目录（如果你使用的是 pycharm，可以通过 pycharm 中的终端）输入指令 <code>tensorboard --logdir="./data/log"</code>，启动服务器。<img src="image-20230508170733748.png" alt="image-20230508170733748"></p>
<blockquote>
<p>logdir 后面的参数是日志文件的文件夹的路径</p>
</blockquote>
<p>然后在谷歌浏览器中访问红框框中的 url，便可得到可视化界面，点击上面的页面控件，可以查看我们通过 <code>add_scalar</code>、<code>add_image</code> 和 <code>add_histogram</code> 得到的图像，而且各方面做得都很丝滑。</p>
<p><img src="image-20230508170745824.png" alt="image-20230508170745824"></p>
<p><img src="image-20230508170805510.png" alt="image-20230508170805510"></p>
<p><img src="image-20230508170817934.png" alt="image-20230508170817934"></p>
<blockquote>
<p>以下是一切安装时候的错误</p>
</blockquote>
<p>好，作为一名<strong>没有装过 TensorFlow</strong>的 windows 玩家，笔者下面开始踩坑。踩完后，直接把几个可能的错误呈上。</p>
<p><strong>第一个错误，运行<code>tensorboard --logdir="./data/log"</code>，遇到报错，内容为有重复的tensorboard的包。</strong></p>
<p>解决方法：找到 site-packages（如果你是像我一样全局安装的，那么找到解释器那一级目录的 site-packages，如果是在项目虚拟环境中安装的，那么找到项目中的 site-packages），删去下图中红框框标出来的文件夹。</p>
<p><img src="image-20230508170831622.png" alt="image-20230508170831622"></p>
<p><strong>第二个错误，在解决第一个错误后，再次运行命令，还是报错，内容为编码出错。</strong> 由于笔者做过一点前端，在学习 webpack 项目时，曾经被告知项目路径不能含有中文，否则会有编码错误，而刚才的报错中涉及到了前端服务器的启动，因此，笔者想到从文件名入手。</p>
<p><strong>解决方法：</strong> 确保命令涉及的文件路径、所有程序涉及到文件不含中文。笔者是计算机名字含有中文，然后 tensorboard 的日志文件是以本地计算机名为后缀的，所以笔者将计算机名修改成了英文，重启后再输入指令就 ok 了。</p>
<h2 id="2-2-HiddenLayer-可视化训练过程"><a href="#2-2-HiddenLayer-可视化训练过程" class="headerlink" title="2.2 HiddenLayer 可视化训练过程"></a>2.2 HiddenLayer 可视化训练过程</h2><p>tensorboard 的图像很华丽，但是使用过程相较于其他的工具包较为繁琐，所以小网络一般没必要使用 tensorboard。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">&nbsp;<span class="keyword">import</span>&nbsp;hiddenlayer&nbsp;<span class="keyword">as</span>&nbsp;hl  </span><br><span class="line">&nbsp;<span class="keyword">import</span>&nbsp;time  </span><br><span class="line">&nbsp;  </span><br><span class="line">&nbsp;<span class="comment">#&nbsp;记录训练过程的指标  </span></span><br><span class="line">&nbsp;history&nbsp;=&nbsp;hl.History()  </span><br><span class="line">&nbsp;<span class="comment">#&nbsp;使用canvas进行可视化  </span></span><br><span class="line">&nbsp;canvas&nbsp;=&nbsp;hl.Canvas()  </span><br><span class="line">&nbsp;  </span><br><span class="line">&nbsp;<span class="comment">#&nbsp;获取优化器和损失函数  </span></span><br><span class="line">&nbsp;optimizer&nbsp;=&nbsp;torch.optim.Adam(MyConvNet.parameters(),&nbsp;lr=<span class="number">3e-4</span>)  </span><br><span class="line">&nbsp;loss_func&nbsp;=&nbsp;nn.CrossEntropyLoss()  </span><br><span class="line">&nbsp;log_step_interval&nbsp;=&nbsp;<span class="number">100</span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;记录的步数间隔  </span></span><br><span class="line">&nbsp;  </span><br><span class="line">&nbsp;<span class="keyword">for</span>&nbsp;epoch&nbsp;<span class="keyword">in</span>&nbsp;<span class="built_in">range</span>(<span class="number">5</span>):  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="built_in">print</span>(<span class="string">"epoch:"</span>,&nbsp;epoch)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;每一轮都遍历一遍数据加载器  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword">for</span>&nbsp;step,&nbsp;(x,&nbsp;y)&nbsp;<span class="keyword">in</span>&nbsp;<span class="built_in">enumerate</span>(train_loader):  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;前向计算-&gt;计算损失函数-&gt;(从损失函数)反向传播-&gt;更新网络  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;predict&nbsp;=&nbsp;MyConvNet(x)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loss&nbsp;=&nbsp;loss_func(predict,&nbsp;y)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;optimizer.zero_grad()&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;清空梯度（可以不写）  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loss.backward()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;反向传播计算梯度  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;optimizer.step()&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;更新网络  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;global_iter_num&nbsp;=&nbsp;epoch&nbsp;*&nbsp;<span class="built_in">len</span>(train_loader)&nbsp;+&nbsp;step&nbsp;+&nbsp;<span class="number">1</span>&nbsp;&nbsp;<span class="comment">#&nbsp;计算当前是从训练开始时的第几步(全局迭代次数)  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword">if</span>&nbsp;global_iter_num&nbsp;%&nbsp;log_step_interval&nbsp;==&nbsp;<span class="number">0</span>:  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;控制台输出一下  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="built_in">print</span>(<span class="string">"global_step:{},&nbsp;loss:{:.2}"</span>.<span class="built_in">format</span>(global_iter_num,&nbsp;loss.item()))  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;在测试集上预测并计算正确率  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;test_predict&nbsp;=&nbsp;MyConvNet(test_data_x)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;_,&nbsp;predict_idx&nbsp;=&nbsp;torch.<span class="built_in">max</span>(test_predict,&nbsp;<span class="number">1</span>)&nbsp;&nbsp;<span class="comment">#&nbsp;计算softmax后的最大值的索引，即预测结果  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;acc&nbsp;=&nbsp;accuracy_score(test_data_y,&nbsp;predict_idx)  </span><br><span class="line">&nbsp;  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;以epoch和step为索引，创建日志字典  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;history.log((epoch,&nbsp;step),  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;train_loss=loss,  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;test_acc=acc,  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;hidden_weight=MyConvNet.fc[<span class="number">2</span>].weight)  </span><br><span class="line">&nbsp;  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;可视化  </span></span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="keyword">with</span>&nbsp;canvas:  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;canvas.draw_plot(history[<span class="string">"train_loss"</span>])  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;canvas.draw_plot(history[<span class="string">"test_acc"</span>])  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;canvas.draw_image(history[<span class="string">"hidden_weight"</span>])</span><br></pre></td></tr></tbody></table></figure>
<blockquote>
<p>不同于 tensorboard，hiddenlayer 会在程序运行的过程中动态生成图像，而不是模型训练完后</p>
</blockquote>
<p>下面为模型训练的某一时刻的截图：<img src="image-20230508170848014.png" alt="image-20230508170848014"></p>
<h1 id="三、使用-Visdom-进行可视化"><a href="#三、使用-Visdom-进行可视化" class="headerlink" title="三、使用 Visdom 进行可视化"></a>三、使用 Visdom 进行可视化</h1><p>Visdom 是 Facebook 为 pytorch 开发的一块可视化工具。类似于 tensorboard，visdom 也是通过在本地启动前端服务器来实现可视化的，而在具体操作上，visdom 又类似于 matplotlib. pyplot。所以使用起来很灵活。</p>
<p>首先先安装visdom库，然后补坑。由于启动前端服务器需要大量依赖项，所以在第一次启动时可能会很慢（需要下载前端三板斧的依赖项），解决方法请见这里。</p>
<p>先导入需要的第三方库：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&nbsp;<span class="keyword">from</span>&nbsp;visdom&nbsp;<span class="keyword">import</span>&nbsp;Visdom  </span><br><span class="line">&nbsp;<span class="keyword">from</span>&nbsp;sklearn.datasets&nbsp;<span class="keyword">import</span>&nbsp;&nbsp;load_iris  </span><br><span class="line">&nbsp;<span class="keyword">import</span>&nbsp;torch  </span><br><span class="line">&nbsp;<span class="keyword">import</span>&nbsp;numpy&nbsp;<span class="keyword">as</span>&nbsp;np  </span><br><span class="line">&nbsp;<span class="keyword">from</span>&nbsp;PIL&nbsp;<span class="keyword">import</span>&nbsp;Image</span><br></pre></td></tr></tbody></table></figure>
<p>matplotlib 里，用户绘图可以通过 plt 这个对象来绘图，在 visdom 中，同样需要一个绘图对象，我们通过 <code>vis = Visdom()</code> 来获取。具体绘制时，由于我们会一次画好几张图，所以 visdom 要求用户在绘制时指定当前绘制图像的窗口名字（也就是 <code>win</code> 这个参数）；除此之外，为了到时候显示的分块，用户还需要指定绘图环境 <code>env</code>，这个参数相同的图像，最后会显示在同一张页面上。</p>
<p>绘制线图（相当于 matplotlib 中的 <code>plt.plot</code>）</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&nbsp;<span class="comment">#&nbsp;绘制图像需要的数据  </span></span><br><span class="line">&nbsp;iris_x,&nbsp;iris_y&nbsp;=&nbsp;load_iris(return_X_y=<span class="literal">True</span>)  </span><br><span class="line">&nbsp;  </span><br><span class="line">&nbsp;<span class="comment">#&nbsp;获取绘图对象，相当于plt  </span></span><br><span class="line">&nbsp;vis&nbsp;=&nbsp;Visdom()  </span><br><span class="line">&nbsp;  </span><br><span class="line">&nbsp;<span class="comment">#&nbsp;添加折线图  </span></span><br><span class="line">&nbsp;x&nbsp;=&nbsp;torch.linspace(-<span class="number">6</span>,&nbsp;<span class="number">6</span>,&nbsp;<span class="number">100</span>).view([-<span class="number">1</span>,&nbsp;<span class="number">1</span>])  </span><br><span class="line">&nbsp;sigmoid&nbsp;=&nbsp;torch.nn.Sigmoid()  </span><br><span class="line">&nbsp;sigmoid_y&nbsp;=&nbsp;sigmoid(x)  </span><br><span class="line">&nbsp;tanh&nbsp;=&nbsp;torch.nn.Tanh()  </span><br><span class="line">&nbsp;tanh_y&nbsp;=&nbsp;tanh(x)  </span><br><span class="line">&nbsp;relu&nbsp;=&nbsp;torch.nn.ReLU()  </span><br><span class="line">&nbsp;relu_y&nbsp;=&nbsp;relu(x)  </span><br><span class="line">&nbsp;<span class="comment">#&nbsp;连接三个张量  </span></span><br><span class="line">&nbsp;plot_x&nbsp;=&nbsp;torch.cat([x,&nbsp;x,&nbsp;x],&nbsp;dim=<span class="number">1</span>)  </span><br><span class="line">&nbsp;plot_y&nbsp;=&nbsp;torch.cat([sigmoid_y,&nbsp;tanh_y,&nbsp;relu_y],&nbsp;dim=<span class="number">1</span>)  </span><br><span class="line">&nbsp;<span class="comment">#&nbsp;绘制线性图  </span></span><br><span class="line">&nbsp;vis.line(X=plot_x,&nbsp;Y=plot_y,&nbsp;win=<span class="string">"line&nbsp;plot"</span>,&nbsp;env=<span class="string">"main"</span>,  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;opts={  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="string">"dash"</span>&nbsp;:&nbsp;np.array([<span class="string">"solid"</span>,&nbsp;<span class="string">"dash"</span>,&nbsp;<span class="string">"dashdot"</span>]),  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="string">"legend"</span>&nbsp;:&nbsp;[<span class="string">"Sigmoid"</span>,&nbsp;<span class="string">"Tanh"</span>,&nbsp;<span class="string">"ReLU"</span>]  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;})</span><br></pre></td></tr></tbody></table></figure>
<p>绘制散点图：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&nbsp;<span class="comment">#&nbsp;添加茎叶图  </span></span><br><span class="line">&nbsp;x&nbsp;=&nbsp;torch.linspace(-<span class="number">6</span>,&nbsp;<span class="number">6</span>,&nbsp;<span class="number">100</span>).view([-<span class="number">1</span>,&nbsp;<span class="number">1</span>])  </span><br><span class="line">&nbsp;y1&nbsp;=&nbsp;torch.sin(x)  </span><br><span class="line">&nbsp;y2&nbsp;=&nbsp;torch.cos(x)  </span><br><span class="line">&nbsp;  </span><br><span class="line">&nbsp;<span class="comment">#&nbsp;连接张量  </span></span><br><span class="line">&nbsp;plot_x&nbsp;=&nbsp;torch.cat([x,&nbsp;x],&nbsp;dim=<span class="number">1</span>)  </span><br><span class="line">&nbsp;plot_y&nbsp;=&nbsp;torch.cat([y1,&nbsp;y2],&nbsp;dim=<span class="number">1</span>)  </span><br><span class="line">&nbsp;<span class="comment">#&nbsp;绘制茎叶图  </span></span><br><span class="line">&nbsp;vis.stem(X=plot_x,&nbsp;Y=plot_y,&nbsp;win=<span class="string">"stem&nbsp;plot"</span>,&nbsp;env=<span class="string">"main"</span>,  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;opts={  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="string">"legend"</span>&nbsp;:&nbsp;[<span class="string">"sin"</span>,&nbsp;<span class="string">"cos"</span>],  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="string">"title"</span>&nbsp;:&nbsp;<span class="string">"茎叶图"</span>  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;})</span><br></pre></td></tr></tbody></table></figure>
<p>绘制热力图：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&nbsp;<span class="comment">#&nbsp;计算鸢尾花数据集特征向量的相关系数矩阵  </span></span><br><span class="line">&nbsp;iris_corr&nbsp;=&nbsp;torch.from_numpy(np.corrcoef(iris_x,&nbsp;rowvar=<span class="literal">False</span>))  </span><br><span class="line">&nbsp;<span class="comment">#&nbsp;绘制热力图  </span></span><br><span class="line">&nbsp;vis.heatmap(iris_corr,&nbsp;win=<span class="string">"heatmap"</span>,&nbsp;env=<span class="string">"main"</span>,  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;opts={  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="string">"rownames"</span>&nbsp;:&nbsp;[<span class="string">"x1"</span>,&nbsp;<span class="string">"x2"</span>,&nbsp;<span class="string">"x3"</span>,&nbsp;<span class="string">"x4"</span>],  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="string">"columnnames"</span>&nbsp;:&nbsp;[<span class="string">"x1"</span>,&nbsp;<span class="string">"x2"</span>,&nbsp;<span class="string">"x3"</span>,&nbsp;<span class="string">"x4"</span>],  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="string">"title"</span>&nbsp;:&nbsp;<span class="string">"热力图"</span>  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;})</span><br></pre></td></tr></tbody></table></figure>
<p>可视化图片，这里我们使用自定义的 env 名 MyPlotEnv</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&nbsp;<span class="comment">#&nbsp;可视化图片  </span></span><br><span class="line">&nbsp;img_Image&nbsp;=&nbsp;Image.<span class="built_in">open</span>(<span class="string">"./example.jpg"</span>)  </span><br><span class="line">&nbsp;img_array&nbsp;=&nbsp;np.array(img_Image.convert(<span class="string">"L"</span>),&nbsp;dtype=np.float32)  </span><br><span class="line">&nbsp;img_tensor&nbsp;=&nbsp;torch.from_numpy(img_array)  </span><br><span class="line">&nbsp;<span class="built_in">print</span>(img_tensor.shape)  </span><br><span class="line">&nbsp;  </span><br><span class="line">&nbsp;<span class="comment">#&nbsp;这次env自定义  </span></span><br><span class="line">&nbsp;vis.image(img_tensor,&nbsp;win=<span class="string">"one&nbsp;image"</span>,&nbsp;env=<span class="string">"MyPlotEnv"</span>,  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;opts={  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="string">"title"</span>&nbsp;:&nbsp;<span class="string">"一张图像"</span>  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;})</span><br></pre></td></tr></tbody></table></figure>
<p>可视化文本，同样在 MyPlotEnv 中绘制：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&nbsp;<span class="comment">#&nbsp;可视化文本  </span></span><br><span class="line">&nbsp;text&nbsp;=&nbsp;<span class="string">"hello&nbsp;world"</span>  </span><br><span class="line">&nbsp;vis.text(text=text,&nbsp;win=<span class="string">"text&nbsp;plot"</span>,&nbsp;env=<span class="string">"MyPlotEnv"</span>,  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;opts={  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="string">"title"</span>&nbsp;:&nbsp;<span class="string">"可视化文本"</span>  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;})</span><br></pre></td></tr></tbody></table></figure>
<p>运行上述代码，再通过在终端中输入 <code>python3 -m visdom.server</code> 启动服务器，然后根据终端返回的 URL，在谷歌浏览器中访问这个 URL，就可以看到图像了。<img src="image-20230508170904960.png" alt="image-20230508170904960"></p>
<p><img src="image-20230508170910418.png" alt="image-20230508170910418"></p>
<blockquote>
<p>在 Environment 中输入不同的 env 参数可以看到我们在不同环境下绘制的图片。对于分类图集特别有用。</p>
</blockquote>
<p>在终端中按下 Ctrl+C 可以终止前端服务器。</p>
<h1 id="进一步"><a href="#进一步" class="headerlink" title="进一步"></a>进一步</h1><p>需要注意，如果你的前端服务器停掉了，那么所有的图片都会丢失，因为此时的图像的数据都是驻留在内存中，而并没有 dump 到本地磁盘。那么如何保存当前 visdom 中的可视化结果，并在将来复用呢？其实很简单，比如我现在有一堆来之不易的 Mel 频谱图：<img src="image-20230508170923964.png" alt="image-20230508170923964"></p>
<p>点击 Manage Views</p>
<p><img src="image-20230508170938623.png" alt="image-20230508170938623"></p>
<p>点击 fork-&gt;save:（此处我只保存名为 normal 的 env）</p>
<p><img src="image-20230508170948224.png" alt="image-20230508170948224"></p>
<p>接着，在你的 User 目录下（Windows 是 C:\Users\账户. visdom 文件夹，Linux 是在~. visdom 文件夹下），可以看到保存好的 env：</p>
<p><img src="image-20230508170958347.png" alt="image-20230508170958347"></p>
<p>它是以 json 文件格式保存的，那么如果你保存完后再 shut down 当前的前端服务器，图像数据便不会丢失。</p>
<p>好的，现在在保存完你珍贵的数据后，请关闭你的visdom前端服务器。然后再启动它。</p>
<p>如何查看保存的数据呢？很简答，下次打开visdom前端后，visdom会在.visdom文件夹下读取所有的保存数据完成初始化，这意味着，你直接启动visdom，其他什么也不用做就可以看到之前保存的数据啦！</p>
<p>那么如何服用保存的数据呢？既然你都知道了 visdom 保存的数据在哪里，那么直接通过 python 的 json 包来读取这个数据文件，然后做解析就可以了，这是方法一，演示如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>&nbsp;json  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">with</span>&nbsp;<span class="built_in">open</span>(<span class="string">r"...\.visdom\normal.json"</span>,&nbsp;<span class="string">"r"</span>,&nbsp;encoding=<span class="string">"utf-8"</span>)&nbsp;<span class="keyword">as</span>&nbsp;f:  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;dataset&nbsp;:&nbsp;<span class="built_in">dict</span>&nbsp;=&nbsp;json.load(f)  </span><br><span class="line">  </span><br><span class="line">jsons&nbsp;:&nbsp;<span class="built_in">dict</span>&nbsp;=&nbsp;dataset[<span class="string">"jsons"</span>]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;这里存着你想要恢复的数据  </span></span><br><span class="line">reload&nbsp;:&nbsp;<span class="built_in">dict</span>&nbsp;=&nbsp;dataset[<span class="string">"reload"</span>]&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;这里存着有关窗口尺寸的数据&nbsp;  </span></span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(jsons.keys())&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;查看所有的win</span></span><br></pre></td></tr></tbody></table></figure>
<p>out:</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dict_keys([<span class="string">'jsons'</span>,&nbsp;<span class="string">'reload'</span>])  </span><br><span class="line">dict_keys([<span class="string">'1.wav'</span>,&nbsp;<span class="string">'2.wav'</span>,&nbsp;<span class="string">'3.wav'</span>,&nbsp;<span class="string">'4.wav'</span>,&nbsp;<span class="string">'5.wav'</span>,&nbsp;<span class="string">'6.wav'</span>,&nbsp;<span class="string">'7.wav'</span>,&nbsp;<span class="string">'8.wav'</span>,&nbsp;<span class="string">'9.wav'</span>,&nbsp;<span class="string">'10.wav'</span>,&nbsp;<span class="string">'11.wav'</span>,&nbsp;<span class="string">'12.wav'</span>,&nbsp;<span class="string">'13.wav'</span>,&nbsp;<span class="string">'14.wav'</span>])</span><br></pre></td></tr></tbody></table></figure>
<p>但这么做不是很优雅，所以 visdom 封装了第二种方法。你当然可以通过访问文件夹. visdom 来查看当前可用的 env，但是也可以这么做：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span>&nbsp;visdom&nbsp;<span class="keyword">import</span>&nbsp;Visdom  </span><br><span class="line">  </span><br><span class="line">vis&nbsp;=&nbsp;Visdom()  </span><br><span class="line"><span class="built_in">print</span>(vis.get_env_list())</span><br></pre></td></tr></tbody></table></figure>
<p>在获取了可用的环境名后，你可以通过 get_window_data 方法来获取指定 env、指定 win 下的图像数据。请注意，该方法返回 str，故需要通过 json 来解析：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span>&nbsp;visdom&nbsp;<span class="keyword">import</span>&nbsp;Visdom  </span><br><span class="line"><span class="keyword">import</span>&nbsp;json  </span><br><span class="line">  </span><br><span class="line">vis&nbsp;=&nbsp;Visdom()  </span><br><span class="line">  </span><br><span class="line">window&nbsp;=&nbsp;vis.get_window_data(win=<span class="string">"1.wav"</span>,&nbsp;env=<span class="string">"normal"</span>)&nbsp;&nbsp;&nbsp;&nbsp;  </span><br><span class="line">window&nbsp;=&nbsp;json.loads(window)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="comment">#&nbsp;window&nbsp;是&nbsp;str，需要解析为字典  </span></span><br><span class="line">  </span><br><span class="line">content&nbsp;=&nbsp;window[<span class="string">"content"</span>]  </span><br><span class="line">data&nbsp;=&nbsp;content[<span class="string">"data"</span>][<span class="number">0</span>]  </span><br><span class="line"><span class="built_in">print</span>(data.keys())</span><br></pre></td></tr></tbody></table></figure>
<p>out:</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Setting&nbsp;up&nbsp;a&nbsp;new&nbsp;session...  </span><br><span class="line">dict_keys([<span class="string">'z'</span>,&nbsp;<span class="string">'x'</span>,&nbsp;<span class="string">'y'</span>,&nbsp;<span class="string">'zmin'</span>,&nbsp;<span class="string">'zmax'</span>,&nbsp;<span class="string">'type'</span>,&nbsp;<span class="string">'colorscale'</span>])</span><br></pre></td></tr></tbody></table></figure>
<p>通过索引这些 keys，相信想复用原本的图像数据并不困难。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://www.zl21.club">浅羡</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://www.zl21.club/2022/11/08/PyTorch%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E3%80%81%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B%E3%80%81%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B7%A5%E5%85%B7%E6%B1%87%E6%80%BB/">https://www.zl21.club/2022/11/08/PyTorch%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E3%80%81%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B%E3%80%81%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B7%A5%E5%85%B7%E6%B1%87%E6%80%BB/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://www.zl21.club" target="_blank">shallow shadow</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/PyTorch/">PyTorch</a><a class="post-meta__tags" href="/tags/%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B7%A5%E5%85%B7/">可视化工具</a></div><div class="post_share"><div class="social-share" data-image="https://images.pexels.com/photos/1252890/pexels-photo-1252890.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=1260&amp;h=750&amp;dpr=2" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer=""></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/11/11/%E5%8F%8C%E7%9B%AE%E8%A7%86%E8%A7%89%E7%BB%BC%E8%BF%B0/" title="双目视觉综述"><img class="cover" src="https://images.pexels.com/photos/1289363/pexels-photo-1289363.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=1260&amp;h=750&amp;dpr=2" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">双目视觉综述</div></div></a></div><div class="next-post pull-right"><a href="/2022/10/08/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%88PyTorch%E6%A1%86%E6%9E%B6%EF%BC%89/" title="动手学深度学习（PyTorch框架）"><img class="cover" src="https://images.pexels.com/photos/36717/amazing-animal-beautiful-beautifull.jpg?auto=compress&amp;cs=tinysrgb&amp;w=1260&amp;h=750&amp;dpr=2" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">动手学深度学习（PyTorch框架）</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/05/08/Python3%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98/" title="Python3网络爬虫开发实战"><img class="cover" src="https://images.pexels.com/photos/1416367/pexels-photo-1416367.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=1260&amp;h=750&amp;dpr=2" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-08</div><div class="title">Python3网络爬虫开发实战</div></div></a></div><div><a href="/2022/11/20/Python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" title="Python数据分析"><img class="cover" src="https://images.pexels.com/photos/891030/pexels-photo-891030.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=1260&amp;h=750&amp;dpr=2" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-20</div><div class="title">Python数据分析</div></div></a></div><div><a href="/2022/10/08/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%88PyTorch%E6%A1%86%E6%9E%B6%EF%BC%89/" title="动手学深度学习（PyTorch框架）"><img class="cover" src="https://images.pexels.com/photos/36717/amazing-animal-beautiful-beautifull.jpg?auto=compress&amp;cs=tinysrgb&amp;w=1260&amp;h=750&amp;dpr=2" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-10-08</div><div class="title">动手学深度学习（PyTorch框架）</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"></div><div class="author-info__name">浅羡</div><div class="author-info__description">蜉蝣之光，照我征途</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">14</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">24</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/anKing97"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/anKing97" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:anking20220315@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎相互交流学习</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="toc-number">1.</span> <span class="toc-text">一、网络结构的可视化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-%E9%80%9A%E8%BF%87-HiddenLayer-%E5%8F%AF%E8%A7%86%E5%8C%96%E7%BD%91%E7%BB%9C"><span class="toc-number">1.1.</span> <span class="toc-text">1.1 通过 HiddenLayer 可视化网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-%E9%80%9A%E8%BF%87-PyTorchViz-%E5%8F%AF%E8%A7%86%E5%8C%96%E7%BD%91%E7%BB%9C"><span class="toc-number">1.2.</span> <span class="toc-text">1.2 通过 PyTorchViz 可视化网络</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="toc-number">2.</span> <span class="toc-text">二、训练过程可视化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-%E9%80%9A%E8%BF%87-tensorboardX-%E5%8F%AF%E8%A7%86%E5%8C%96%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B"><span class="toc-number">2.1.</span> <span class="toc-text">2.1 通过 tensorboardX 可视化训练过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-HiddenLayer-%E5%8F%AF%E8%A7%86%E5%8C%96%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B"><span class="toc-number">2.2.</span> <span class="toc-text">2.2 HiddenLayer 可视化训练过程</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E4%BD%BF%E7%94%A8-Visdom-%E8%BF%9B%E8%A1%8C%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="toc-number">3.</span> <span class="toc-text">三、使用 Visdom 进行可视化</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%BF%9B%E4%B8%80%E6%AD%A5"><span class="toc-number">4.</span> <span class="toc-text">进一步</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/02/12/Ubuntu%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5/" title="Ubuntu系统实践"><img src="https://images.pexels.com/photos/325185/pexels-photo-325185.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=1260&amp;h=750&amp;dpr=2" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Ubuntu系统实践"></a><div class="content"><a class="title" href="/2023/02/12/Ubuntu%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5/" title="Ubuntu系统实践">Ubuntu系统实践</a><time datetime="2023-02-12T10:19:33.000Z" title="发表于 2023-02-12 18:19:33">2023-02-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/02/10/Nas%E5%AE%9E%E8%B7%B5/" title="Nas实践"><img src="https://images.pexels.com/photos/327509/pexels-photo-327509.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=1260&amp;h=750&amp;dpr=2" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Nas实践"></a><div class="content"><a class="title" href="/2023/02/10/Nas%E5%AE%9E%E8%B7%B5/" title="Nas实践">Nas实践</a><time datetime="2023-02-10T10:14:18.000Z" title="发表于 2023-02-10 18:14:18">2023-02-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/01/13/WSL%E5%AE%9E%E8%B7%B5/" title="WSL实践"><img src="https://images.pexels.com/photos/2915997/pexels-photo-2915997.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=1260&amp;h=750&amp;dpr=2" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="WSL实践"></a><div class="content"><a class="title" href="/2023/01/13/WSL%E5%AE%9E%E8%B7%B5/" title="WSL实践">WSL实践</a><time datetime="2023-01-13T10:27:00.000Z" title="发表于 2023-01-13 18:27:00">2023-01-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/01/07/Vue3%E6%80%BB%E7%BB%93/" title="Vue3总结"><img src="https://images.pexels.com/photos/813871/pexels-photo-813871.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=1260&amp;h=750&amp;dpr=2" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Vue3总结"></a><div class="content"><a class="title" href="/2023/01/07/Vue3%E6%80%BB%E7%BB%93/" title="Vue3总结">Vue3总结</a><time datetime="2023-01-07T10:31:51.000Z" title="发表于 2023-01-07 18:31:51">2023-01-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/21/SpringCloud%E5%90%8E%E7%AB%AF%E6%90%AD%E5%BB%BA%E6%AD%A5%E9%AA%A4/" title="SpringCloud后端搭建步骤"><img src="https://images.pexels.com/photos/1037992/pexels-photo-1037992.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=1260&amp;h=750&amp;dpr=2" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SpringCloud后端搭建步骤"></a><div class="content"><a class="title" href="/2022/12/21/SpringCloud%E5%90%8E%E7%AB%AF%E6%90%AD%E5%BB%BA%E6%AD%A5%E9%AA%A4/" title="SpringCloud后端搭建步骤">SpringCloud后端搭建步骤</a><time datetime="2022-12-21T15:30:41.000Z" title="发表于 2022-12-21 23:30:41">2022-12-21</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent"><div id="footer-wrap"><div class="copyright">©2021 - 2023 By 浅羡</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"></div><script async="" data-pjax="" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>